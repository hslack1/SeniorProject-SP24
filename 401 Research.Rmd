---
title: "401 Research"
author: "Holston Slack"
date: "2/29/2024"
output: html_document
---
```{r}
library (readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(gridExtra)
library(data.table)
library(patchwork)
library(tidyverse)
library(jsonlite)
library(car)   # For VIF calculation
library(lmtest)
```

```{r}
credits <- read.csv("credits.csv")
keywords <- read.csv("keywords.csv")
ratings <- read.csv ("ratings.csv")
links <- read.csv("links.csv")
sequels <- read.csv("movies_metadata.csv")
```

```{r}
#merges 2 datasets and joins based off common column
df_combined <- merge(ratings, links, by = "movieId")
```

```{r}
meta <- read.csv("movies_metadata.csv")
meta <- meta %>%
  filter(original_language == "en") %>% 
  filter(as.numeric(str_sub(release_date, 1, 4)) >= 1970 & 
         as.numeric(str_sub(release_date, 1, 4)) <= 2020)%>%
  filter(revenue >= 100) %>%
  filter(budget >=100)

nonsequels <- meta %>%
  filter(is.na(meta$belongs_to_collection) | nchar(meta$belongs_to_collection) == 0) 

sequels <- meta %>%
  filter(str_detect(belongs_to_collection, "\\{"))

sequels <- sequels %>% 
  rename(tmdbId = id)
```


```{r}
df_combined <- merge(df_combined, sequels, by = "tmdbId")
```


```{r}
df_combined <- df_combined %>%
  filter(original_language == "en") %>% 
  filter(as.numeric(str_sub(release_date, 1, 4)) >= 1970 & 
         as.numeric(str_sub(release_date, 1, 4)) <= 2020)
```

Working to regex the title from belongs_to column; string; incomplete

```{r}
extract_between_commas <- function(text) {
  # Split the text by commas using str_split
  split_text <- str_split(text, ",")[[1]]  # Split text, take the first element (vector of substrings)
  
  # Check if there are at least 3 commas (ensure enough elements for 2nd and 3rd comma)
  if (length(split_text) >= 3) {
    # Return the text between 2nd and 3rd comma (excluding commas)
    return(split_text[2])
  } else {
    # If there are less than 3 commas, return an empty string
    return("")
  }
}

sequels$franchise <- lapply(sequels$belongs_to_collection, extract_between_commas)

```

```{r}
# Function to extract text between 3rd and 4th apostrophes
extract_between_apostrophes <- function(text) {
  # Split the text by apostrophes using str_split
  split_text <- str_split(text, "'")[[1]]  # Split text, take the first element (vector of substrings)
  
  # Check if there are at least 4 apostrophes (ensure enough elements for 3rd and 4th)
  if (length(split_text) >= 5) {
    # Extract the text between 3rd and 4th apostrophe (excluding apostrophes)
    extracted_text <- split_text[4]
    
    # Remove "collection" if it exists at the end
    extracted_text <- str_trim(extracted_text, side = "right")  # Remove trailing whitespace
    extracted_text <- gsub(" collection$", "", extracted_text, ignore.case = TRUE)  # Remove " collection" at the end 
    
    return(extracted_text)
  } else {
    # If there are less than 4 apostrophes, return an empty string
    return("")
  }
}

# Apply the function to the "text_column"
sequels$belongs_to_collection <- lapply(sequels$franchise, extract_between_apostrophes)

sequels <- sequels[, !(colnames(sequels) %in% c("timestamp","lanchise","franchise", "collection"))]

```


```{r}
data <- sequels$genres

# Regular expression to capture characters after 20th position until next '
pattern <- "(?<=.{20})([^']+)"

captured_letters <- character()  # Initialize empty character vector

for (i in 1:length(data)) {
  # Extract text for each element (string) in the vector
  current_letters <- str_extract_all(data[i], pattern) %>% unlist()
  captured_letters <- c(captured_letters, current_letters)  # Append extracted letters
}

# Remove empty strings (optional)
captured_letters <- captured_letters[!captured_letters == ""]
```

```{r}
nonsequels <- nonsequels[, !(colnames(nonsequels) %in% c( "adult", "homepage", "poster_path", "spoken_languages", "status", "tagline", "video", "imdb_id", "overview"))]

sequels <- sequels[, !(colnames(sequels) %in% c("timestamp", "adult", "homepage", "poster_path", "spoken_languages", "status", "tagline", "video", "imdb_id", "overview"))]
```


```{r}
data_type <- typeof(sequels$budget)

if (data_type != "numeric") {
  sequels$revenue <- as.numeric(sequels$revenue)
}
seqfig1 <- ggplot(sequels, aes(x = revenue)) +
  geom_histogram(binwidth = 250000000, fill = "lightblue", color = "black") +  # Adjust binwidth
  theme_minimal() +
  labs(title = "Fig. 1 Distribution of Revenue Amongst Sequels", x = "Revenue (M)", y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 3e9, by = 2.5e+8),  # Labels every 500 million
                     labels = scales::number_format(scale = 1e-6, suffix = "M"))  
seqfig1


# If it's not numeric, convert it (assuming it's a character vector containing numbers)
if (data_type != "numeric") {
  sequels$budget <- as.numeric(sequels$budget)
}
seqfig2 <- ggplot(sequels, aes(x = budget)) +
  geom_histogram(binwidth = 50000000, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_minimal() +
  labs(title = "Fig 2. Distribution of Budget Amongst Sequels", x = "Budget (M)", y = "Frequency")+
  scale_x_continuous(breaks = seq(0, 380e6, by = 50e6),  # Labels every 50 million
                   labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as millions

seqfig2
```


```{r}
data_type <- typeof(nonsequels$budget)

if (data_type != "numeric") {
  nonsequels$revenue <- as.numeric(nonsequels$revenue)
}
fig1 <- ggplot(nonsequels, aes(x = revenue)) +
  geom_histogram(binwidth = 250000000, fill = "lightblue", color = "black") +  # Adjust binwidth
  theme_minimal() +
  labs(title = "Fig. 2 Distribution of Revenue Amongst Non-Sequels", x = "Revenue (M)", y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 3e9, by = 2.5e+8),  # Labels every 500 million
                     labels = scales::number_format(scale = 1e-6, suffix = "M"))
fig1


# If it's not numeric, convert it (assuming it's a character vector containing numbers)
if (data_type != "numeric") {
  nonsequels$budget <- as.numeric(nonsequels$budget)
}
fig2 <- ggplot(nonsequels, aes(x = budget)) +
  geom_histogram(binwidth = 50000000, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_minimal() +
  labs(title = "Distribution of Budget Amongst Non-Sequels", x = "Budget (M)", y = "Frequency")+
  scale_x_continuous(breaks = seq(0, 380e6, by = 50e6),  # Labels every 50 million
                   labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as millions

fig2
```


```{r}
seqdist <- grid.arrange(seqfig1, fig1, nrow = 2)
nondist <- grid.arrange(fig1, fig2, nrow = 2)
```

creating variables

number- this variable identifies the number for each movie in the franchise
Add a number for each movie in the franchise

Filter out movies that belonged to a franchise but there was only one movie in the franchise

```{r}
#format the franchise so it is not a list
extracted_data <- sapply(sequels$belongs_to_collection, `[[`, 1)
sequels$collection_info <- extracted_data 

sequels <- sequels %>%
  group_by(collection_info) %>%
  mutate(number = rank(release_date))

sequels <- sequels %>%
  group_by(collection_info) %>%
  filter(!all(number == 1))  # Filter groups where NOT all numbers are 1

sequelsonly <- sequels %>%
  filter(number>1)

firstmovie <- sequels %>%
  filter(number == 1) %>%
  filter(budget > 1000000)

```




```{r}
data_type <- typeof(nonsequels$budget)

if (data_type != "numeric") {
  sequelsonly$revenue <- as.numeric(sequelsonly$revenue)
}
ffig1 <- ggplot(sequelsonly, aes(x = revenue)) +
  geom_histogram(binwidth = 250000000, fill = "lightblue", color = "black") +  # Adjust binwidth
  theme_grey() +
  labs(title = "Fig. 1 Distribution of Revenue Amongst Sequels", x = "Revenue (M)", y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 3e9, by = 2.5e+8),  # Labels every 500 million
                     labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as
ffig1


# If it's not numeric, convert it (assuming it's a character vector containing numbers)
if (data_type != "numeric") {
  sequelsonly$vote_average <- as.numeric(sequelsonly$vote_average)
}
ffig2 <- ggplot(sequelsonly, aes(x = vote_average)) +
  geom_histogram(binwidth = .5, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_grey() +
  labs(title = "Fig. 2 Distribution of Vote Average Amongst Sequels", x = "Vote Average", y = "Frequency")


ffig2


```


```{r}

if (data_type != "numeric") {
  sequelsonly$runtime <- as.numeric(sequelsonly$runtime)
}
ffig3 <- ggplot(sequelsonly, aes(x = runtime)) +
  geom_histogram(binwidth = 25, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_grey() +
  labs(title = "Fig. 3 Distribution of Runtime Amongst Sequels", x = "Runtime (Minutes)", y = "Frequency") 

ffig3


if (data_type != "numeric") {
  sequelsonly$budget <- as.numeric(sequelsonly$budget)
}
ffig4 <- ggplot(sequelsonly, aes(x = budget)) +
  geom_histogram(binwidth = 25000000, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_grey() +
  labs(title = "Fig. 4 Distribution of Budget Amongst Sequels", x = "Budget (M)", y = "Frequency")+
  scale_x_continuous(breaks = seq(0, 380e6, by = 50e6),  # Labels every 50 million
                   labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as millions
ffig4
```

```{r}
independentdist <- grid.arrange(ffig1, ffig2, ffig3, ffig4, nrow = 2)
```

```{r}
# creates subsets to run correlation matrixes on to verify assumption of no co-linearity

sub_sequel <- sequels [, c("budget", "runtime", "vote_average", "revenue")]
correlation_matrix <- cor(sub_sequel, use = "pairwise")

sub_sequelonly <- sequelsonly [, c("budget", "runtime", "vote_average", "revenue")]
correlation_matrixseqonly <- cor(sub_sequelonly, use = "pairwise")
correlation_matrixseqonly

```

```{r}
if (any(sequelsonly$budget <= 0)) {
  # Add a small constant (adjust as needed)
  data_adjusted <- sequelsonly$budget + 1
} else {
  data_adjusted <- sequelsonly$budget
}

# Apply log transformation (base-10 in this example)
sqrtnumber <- sqrt(data_adjusted)
sqrtnumber <- sqrt(sqrtnumber)
sqrtnumber <- sqrt(sqrtnumber)
# Test normality of log-transformed data
shapiro.test(sqrtnumber)

logqqdata <- sqrtnumber
sequelsonly$sqrt_budget <- logqqdata
theoretical_quantiles <- rnorm(length(logqqdata), mean(logqqdata), sd(logqqdata))

qq_sqrtbudget <- qqplot(logqqdata, theoretical_quantiles,
       main="Q-Q Plot of Budget Data", 
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")
```


```{r}
# Square root transformation
rqqdata <- sequelsonly$runtime
runtimetransformed <- sqrt(rqqdata)
runtimetransformed <- sqrt(runtimetransformed)
runtimetransformed <- sqrt(runtimetransformed)
shapiro.test(runtimetransformed)


sequelsonly$runtime_sqrt <- runtimetransformed

theoretical_quantiles <- rnorm(length(runtimetransformed), mean(runtimetransformed), sd(runtimetransformed))
qq_runtime <- qqplot(runtimetransformed, theoretical_quantiles,
       main="Q-Q Plot of Runtime Data", 
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")
```

```{r}
# no need to be transformed
qqdata <- sequelsonly$vote_average

theoretical_quantiles <- rnorm(length(qqdata), mean(qqdata), sd(qqdata))
shapiro.test(qqdata)
qq_vote_avg <- qqplot(qqdata, theoretical_quantiles,
       main="Q-Q Plot of Vote Average", 
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")

```

```{r}
if (!require("gridExtra")) install.packages("gridExtra")
library(gridExtra)

if (any(sequelsonly$number <= 0)) {
  # Add a small constant (adjust as needed)
  data_adjusted <- sequelsonly$number + 1
} else {
  data_adjusted <- sequelsonly$number
}

sqrtnumber <- sqrt(data_adjusted)


shapiro.test(sqrtnumber)

# Apply log transformation (base-10 in this example)
lognumber <- log10(data_adjusted)

# Test normality of log-transformed data
shapiro.test(lognumber)


qq_numberdata <- sqrtnumber

theoretical_quantiles <- rnorm(length(qq_numberdata), mean(qq_numberdata), sd(qq_numberdata))
qq_number <- qqplot(qq_numberdata, theoretical_quantiles,
       main="Q-Q Plot of Movie Number", 
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")

sequelsonly$sqrt_budget <- logqqdata
sequelsonly$sqrt_number <- lognumber
```

```{r}
# visualizes budget vs revenue
linfig1 <- ggplot(sequelsonly, aes(x = sqrt_budget, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Budget (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  xlab("Budget") +
  ylab("Revenue") +
  theme_grey()
```

```{r}
# visualizes runtime vs revenue
linfig2 <- ggplot(sequelsonly, aes(x = runtime_sqrt, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Runtime (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
 
  xlab("Runtime") +
  ylab("Revenue") +
  theme_grey()
```


```{r}
# visualizes ovote average vs revenue
linfig3 <- ggplot(sequelsonly, aes(x = vote_average, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Vote Average Out of 10 (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  
  xlab("Vote Average Out of 10") +
  ylab("Revenue") +
  theme_grey()
```


```{r}
#compares independent variables between movies that recieved a sequel and nonsequel movies

new_min <- 50  # Adjust this value as needed (minimum runtime)
new_max <- 210  # Adjust this value as needed (maximum runtime)


combined_data <- rbind(
  data.frame(runtime = firstmovie$runtime, category = "Movies that Recieved a Sequel"),
  data.frame(runtime = nonsequels$runtime, category = "Non-Sequels")
)

# Calculate means for each category
mean_runtime <- aggregate(runtime ~ category, combined_data, mean)

# Create the density plot
densityplot <- ggplot(combined_data, aes(x = runtime, color = category)) +
  geom_density(alpha = 0.5) +
  geom_vline(data = mean_runtime, aes(xintercept = runtime, color = category), linetype = "dashed") +  # Add mean lines
  labs(title = "Density Plot of Runtime", x = "Runtime", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max)) +  # Set new limits
  scale_color_manual(values = c("royalblue", "orange")) +  # Set colors for each category
  annotate("text", x = mean_runtime$runtime[1], y = 0.01, label = paste("Mean:", round(mean_runtime$runtime[1], 2)), color = "royalblue", size = 3, hjust = 1, vjust = 12) +  # Label for mean of category 1
  annotate("text", x = mean_runtime$runtime[2], y = 0.01, label = paste("Mean:", round(mean_runtime$runtime[2], 2)), color = "orange", size = 3, hjust = -0.1, vjust = 10)  # Label for mean of category 2

densityplot
```

```{r}
# compares vote average between sequel and nonsequel movies

new_min <- 0  # Adjust this value as needed (minimum vote average)
new_max <- 10  # Adjust this value as needed (maximum vote average)

# Convert data type to numeric if needed
if (data_type != "numeric") {
  firstmovie$vote_average <- as.numeric(firstmovie$vote_average)
  nonsequels$vote_average <- as.numeric(nonsequels$vote_average)
}

# Combine data into a single data frame with a "category" variable
combined_data <- rbind(
  data.frame(vote_average = firstmovie$vote_average, category = "Movies that Received a Sequel"),
  data.frame(vote_average = nonsequels$vote_average, category = "Non-Sequels")
)

# Calculate means for each category
mean_vote_average <- aggregate(vote_average ~ category, combined_data, mean)

# Check the structure of mean_vote_average
str(mean_vote_average)

# Create the density plot
densityplot <- ggplot(combined_data, aes(x = vote_average, color = category)) +
  geom_density(alpha = 0.5) +
  geom_vline(data = mean_vote_average, aes(xintercept = vote_average, color = category), linetype = "dashed") +  # Add mean lines
  labs(title = "Density Plot of Vote Average", x = "Vote Average", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max)) +  # Set new limits
  scale_color_manual(values = c("royalblue", "orange")) +  # Set colors for each category
  annotate("text", x = mean_vote_average$vote_average[1], y = 0.01, label = paste("Mean:", round(mean_vote_average$vote_average[1], 2)), color = "royalblue", size = 3, hjust = -.31, vjust = -30) +  # Label for mean of category 1
  annotate("text", x = mean_vote_average$vote_average[2], y = 0.01, label = paste("Mean:", round(mean_vote_average$vote_average[2], 2)), color = "orange", size = 3, hjust = 1, vjust = -30)  # Label for mean of category 2

densityplot
```


```{r}
new_min <- 0  # Adjust this value as needed (minimum budget)
new_max <- 200000000  # Adjust this value as needed (maximum budget)

# Convert data type to numeric if needed
if (data_type != "numeric") {
  firstmovie$budget <- as.numeric(firstmovie$budget)
  nonsequels$budget <- as.numeric(nonsequels$budget)
}

# Combine data into a single data frame with a "category" variable
combined_dataa <- rbind(
  data.frame(budget = firstmovie$budget, category = "Movies that Received a Sequel"),
  data.frame(budget = nonsequels$budget, category = "Non-Sequels")
)

# Calculate means for each category
mean_budget <- aggregate(budget ~ category, combined_dataa, mean)

# Check the structure of mean_budget
str(mean_budget)

# Create the density plot
densityplot <- ggplot(combined_dataa, aes(x = budget, color = category)) +
  geom_density(alpha = 0.5) +
  geom_vline(data = mean_budget, aes(xintercept = budget, color = category), linetype = "dashed") +  # Add mean lines
  labs(title = "Density Plot of Budget", x = "Budget", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max), labels = scales::comma) +  # Set new limits and format labels as comma-separated
  scale_color_manual(values = c("royalblue", "orange")) +  # Set colors for each category
  annotate("text", x = mean_budget$budget[1], y = 0.0000008, label = paste("Mean:", scales::comma(round(mean_budget$budget[1], 2))), color = "royalblue", size = 3, hjust = -0.1, vjust = -1) +  # Label for mean of category 1
  annotate("text", x = mean_budget$budget[2], y = 0.0000008, label = paste("Mean:", scales::comma(round(mean_budget$budget[2], 2))), color = "orange", size = 3, hjust = -0.1, vjust = -1)  # Label for mean of category 2

densityplot
```


Working to seperate genre

```{r}
# unpacks JSON format of genre

json_column <- sequelsonly$genres 

# Function to correct JSON format
correct_json <- function(json_string) {
  # Replace single quotes with double quotes
  corrected_json <- gsub("'", "\"", json_string)
  return(corrected_json)
}

# Apply the correct_json function to each element of the json_column
corrected_json_column <- sapply(json_column, correct_json)

# Initialize a list to store the extracted names
all_names <- list()

# Loop through each element of the corrected_json_column
for (json_string in corrected_json_column) {
  # Parse the JSON string in the current row
  parsed_json <- jsonlite::fromJSON(json_string)
  
  # Extract the value of the 'name' key
  names <- parsed_json$name
  
  # Store the extracted names in the list
  all_names <- c(all_names, list(names))
}

# Determine the maximum number of genres in any movie
max_genres <- max(lengths(all_names))

# Pad shorter lists with NA to make them the same length
all_names <- lapply(all_names, function(x) c(x, rep(NA, max_genres - length(x))))

# Convert the list to a dataframe
all_names_df <- as.data.frame(do.call(rbind, all_names))

# Rename the columns
colnames(all_names_df) <- paste0("genress_", 1:max_genres)

# Join the extracted genre columns with the original dataset
sequelsonly <- cbind(sequelsonly, all_names_df)

# Print the joined dataframe
print(sequelsonly)

```

```{r}
#pivots sequel dataset so each row is a single observation
movies_long <- sequelsonly %>%
  pivot_longer(cols = starts_with("Genress"),
               names_to = "Genre_Column",
               values_to = "Genre") %>%
  filter(!is.na(Genre))  # Remove rows with missing genre values
```

Calculating HSD to quantify the magnitude of differences in revenue between genres. Will help understand the significance of observed differences from anova

```{r}


# Perform ANOVA
model <- lm(revenue ~ Genre, data = movies_long)
anova_result <- anova(model)

# Check the ANOVA result
print(anova_result)

# If the ANOVA is significant, proceed with Tukey's HSD test
if (anova_result$`Pr(>F)`[1] < 0.05) {
  tukey_result <- TukeyHSD(aov(model))
  print(tukey_result)
  
  significant_pairs <- as.data.frame(tukey_result$`Genre`)  # Extract pairs and adjusted p-values
  significant_pairs <- significant_pairs[significant_pairs$`p adj` < 0.05, ]  # Filter significant pairs
  print(significant_pairs)
  
  
}

```


```{r}


# Perform ANOVA
model <- lm(revenue ~ Genre, data = movies_long)
anova_result <- anova(model)

# Check the ANOVA result
print(anova_result)

# If the ANOVA is significant, proceed with Tukey's HSD test
if (anova_result$`Pr(>F)`[1] < 0.05) {
  tukey_result <- TukeyHSD(aov(model))
  print(tukey_result)
  
  # Extract significant pairs and adjusted p-values
  significant_pairs <- as.data.frame(tukey_result$`Genre`)
  significant_pairs <- significant_pairs[significant_pairs$`p adj` < 0.05, ]
  ## ADD TO APENDIX
  print(significant_pairs)
  
  # Visualize significant pairs
  barplot(significant_pairs$diff, names.arg = rownames(significant_pairs), ylim = c(min(significant_pairs$lwr), max(significant_pairs$upr)),
          xlab = "Genre Comparison", ylab = "Mean Difference", main = "Significant Genre Differences")
  
  # Add error bars
  arrows(x0 = 1:nrow(significant_pairs), y0 = significant_pairs$diff, y1 = significant_pairs$lwr, angle = 90, code = 3, length = 0.1)
} else {
  print("ANOVA is not significant, no need for post-hoc tests.")
}
```

```{r}

# calculating the mean revenue for each genre
avg_revenue <- movies_long %>%
  group_by(Genre) %>%
  summarise(avg_revenue = mean(revenue))

# Now, plot the aggregated data
ggplot(avg_revenue, aes(x = reorder(Genre, avg_revenue), y = avg_revenue)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  geom_text(aes(label = scales::dollar(avg_revenue)), hjust = 1, color = "black", size = 3) +  # Add labels for average revenue
  labs(title = "Fig 11. Average Revenue by Genre (Sequels Only)", x = "Genre", y = "Average Revenue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar_format(prefix = "$"), breaks = seq(0, 500000000, by = 100000000))
```


```{r}


# Fit linear regression model
lm_model<- lm(revenue ~ sqrt_budget + vote_average + runtime_sqrt, data = sequelsonly)


residuals <- residuals(lm_model)

summary(lm_model)
#assumption
# Check for homoscedasticity
# little bit of a funnel shape but no clear patterns are present
plott1<- plot(lm_model, which = 1, main = "Fig 5. Plot of Residuals vs Fitted Values")


#shows the residuals are normally distributed
histogram_resid <- ggplot(data.frame(residuals), aes(x = residuals)) +
  geom_histogram(bins = 20, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(x = "Residuals", y = "Frequency", title = "Fig. 6 Histogram of Residuals")

#add each independent variable vs dependent variable to assumptions
# checking for linearity between independent and dependent variable
linfig1
linfig2
linfig3

plotss <- grid.arrange(linfig1, linfig2, linfig3)



library(ggplot2)
library(patchwork)
library(ggcorrplot)

# Assuming correlation_matrixseqonly is a correlation matrix object
# Convert correlation_matrixseqonly to a ggplot object
correlation_ggplot <- ggcorrplot(correlation_matrixseqonly, type = "upper", lab = TRUE)

# Combine all plots using patchwork
combined_plots <- (plott1 /histogram_resid)

# Display the combined plot
print(combined_plots)

shapiro.test(sqrtnumber)
shapiro.test(runtimetransformed)
shapiro.test(qqdata)
```

```{r}
## post-hoc

confint(lm_model)


# Diagnostic plots
par(mfrow = c(2, 2))  # Set up a 2x2 layout for plots
plot(lm_model, which = c( 2, 3, 4, 5), main = "Post-Hoc Tests for Linear Regression Model")  # Plot diagnostics, including residuals vs. fitted values, residuals vs. predictor variables, etc.
qqnorm(residuals(lm_model))  # Q-Q plot for residuals
qqline(residuals(lm_model))  # Add a line to the Q-Q plot

# Formal statistical tests
# Test for homoscedasticity
library(lmtest)  # Load the lmtest package
bptest(lm_model)  # Breusch-Pagan test for heteroscedasticity

# Test for normality of residuals
shapiro.test(residuals(lm_model))  # Shapiro-Wilk test for normality
```


