---
title: "401 Research"
author: "Holston Slack"
date: "2/29/2024"
output: html_document
---
```{r}
library (readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(gridExtra)
library(data.table)
library(patchwork)
library(tidyverse)
library(stats)
library(jsonlite)
```

```{r}
credits <- read.csv("credits.csv")
keywords <- read.csv("keywords.csv")
ratings <- read.csv ("ratings.csv")
links <- read.csv("links.csv")
sequels <- read.csv("movies_metadata.csv")
```

```{r}
#merges 2 datasets and joins based off common column
df_combined <- merge(ratings, links, by = "movieId")
```

```{r}
meta <- read.csv("movies_metadata.csv")
meta <- meta %>%
  filter(original_language == "en") %>% 
  filter(as.numeric(str_sub(release_date, 1, 4)) >= 1970 & 
         as.numeric(str_sub(release_date, 1, 4)) <= 2020)%>%
  filter(revenue >= 100) %>%
  filter(budget >=100)

nonsequels <- meta %>%
  filter(is.na(meta$belongs_to_collection) | nchar(meta$belongs_to_collection) == 0) 

sequels <- meta %>%
  filter(str_detect(belongs_to_collection, "\\{"))

sequels <- sequels %>% 
  rename(tmdbId = id)
```


```{r}
df_combined <- merge(df_combined, sequels, by = "tmdbId")
```


```{r}
df_combined <- df_combined %>%
  filter(original_language == "en") %>% 
  filter(as.numeric(str_sub(release_date, 1, 4)) >= 1970 & 
         as.numeric(str_sub(release_date, 1, 4)) <= 2020)
```

Working to regex the title from belongs_to column; string; incomplete

```{r}
extract_between_commas <- function(text) {
  # Split the text by commas using str_split
  split_text <- str_split(text, ",")[[1]]  # Split text, take the first element (vector of substrings)
  
  # Check if there are at least 3 commas (ensure enough elements for 2nd and 3rd comma)
  if (length(split_text) >= 3) {
    # Return the text between 2nd and 3rd comma (excluding commas)
    return(split_text[2])
  } else {
    # If there are less than 3 commas, return an empty string
    return("")
  }
}

# Apply the function to the "text_column"
sequels$franchise <- lapply(sequels$belongs_to_collection, extract_between_commas)

# Assuming your data is in a data frame named 'data' and the column with text is named 'text_column'
```

```{r}
# Function to extract text between 3rd and 4th apostrophes
extract_between_apostrophes <- function(text) {
  # Split the text by apostrophes using str_split
  split_text <- str_split(text, "'")[[1]]  # Split text, take the first element (vector of substrings)
  
  # Check if there are at least 4 apostrophes (ensure enough elements for 3rd and 4th)
  if (length(split_text) >= 5) {
    # Extract the text between 3rd and 4th apostrophe (excluding apostrophes)
    extracted_text <- split_text[4]
    
    # Remove "collection" (case-insensitive) if it exists at the end
    extracted_text <- str_trim(extracted_text, side = "right")  # Remove trailing whitespace
    extracted_text <- gsub(" collection$", "", extracted_text, ignore.case = TRUE)  # Remove " collection" at the end (case-insensitive)
    
    return(extracted_text)
  } else {
    # If there are less than 4 apostrophes, return an empty string
    return("")
  }
}

# Apply the function to the "text_column"
sequels$belongs_to_collection <- lapply(sequels$franchise, extract_between_apostrophes)

sequels <- sequels[, !(colnames(sequels) %in% c("timestamp","lanchise","franchise", "collection"))]

```


```{r}
data <- sequels$genres

# Regular expression to capture characters after 20th position (inclusive) until next '
pattern <- "(?<=.{20})([^']+)"

captured_letters <- character()  # Initialize empty character vector

for (i in 1:length(data)) {
  # Extract text for each element (string) in the vector
  current_letters <- str_extract_all(data[i], pattern) %>% unlist()
  captured_letters <- c(captured_letters, current_letters)  # Append extracted letters
}

# Remove empty strings (optional)
captured_letters <- captured_letters[!captured_letters == ""]
view(captured_letters)
```

```{r}
nonsequels <- nonsequels[, !(colnames(sequels) %in% c("timestamp", "adult", "homepage", "poster_path", "spoken_languages", "status", "tagline", "video", "imdb_id", "overview"))]

sequels <- sequels[, !(colnames(sequels) %in% c("timestamp", "adult", "homepage", "poster_path", "spoken_languages", "status", "tagline", "video", "imdb_id", "overview"))]
```


```{r}
data_type <- typeof(sequels$budget)

if (data_type != "numeric") {
  sequels$revenue <- as.numeric(sequels$revenue)
}
seqfig1 <- ggplot(sequels, aes(x = revenue)) +
  geom_histogram(binwidth = 250000000, fill = "lightblue", color = "black") +  # Adjust binwidth
  theme_minimal() +
  labs(title = "Fig. 1 Distribution of Revenue Amongst Sequels", x = "Revenue (M)", y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 3e9, by = 2.5e+8),  # Labels every 500 million
                     labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as
seqfig1


# If it's not numeric, convert it (assuming it's a character vector containing numbers)
if (data_type != "numeric") {
  sequels$budget <- as.numeric(sequels$budget)
}
seqfig2 <- ggplot(sequels, aes(x = budget)) +
  geom_histogram(binwidth = 50000000, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_minimal() +
  labs(title = "Fig 2. Distribution of Budget Amongst Sequels", x = "Budget (M)", y = "Frequency")+
  scale_x_continuous(breaks = seq(0, 380e6, by = 50e6),  # Labels every 50 million
                   labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as millions

seqfig2
```


```{r}
data_type <- typeof(nonsequels$budget)

if (data_type != "numeric") {
  nonsequels$revenue <- as.numeric(nonsequels$revenue)
}
fig1 <- ggplot(nonsequels, aes(x = revenue)) +
  geom_histogram(binwidth = 250000000, fill = "lightblue", color = "black") +  # Adjust binwidth
  theme_minimal() +
  labs(title = "Fig. 2 Distribution of Revenue Amongst Non-Sequels", x = "Revenue (M)", y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 3e9, by = 2.5e+8),  # Labels every 500 million
                     labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as
fig1


# If it's not numeric, convert it (assuming it's a character vector containing numbers)
if (data_type != "numeric") {
  nonsequels$budget <- as.numeric(nonsequels$budget)
}
fig2 <- ggplot(nonsequels, aes(x = budget)) +
  geom_histogram(binwidth = 50000000, fill = "lightblue", color = "black") +  # Adjust binwidth as needed
  theme_minimal() +
  labs(title = "Distribution of Budget Amongst Non-Sequels", x = "Budget (M)", y = "Frequency")+
  scale_x_continuous(breaks = seq(0, 380e6, by = 50e6),  # Labels every 50 million
                   labels = scales::number_format(scale = 1e-6, suffix = "M"))  # Format as millions

fig2
```


```{r}
seqdist <- grid.arrange(seqfig1, fig1, nrow = 2)
nondist <- grid.arrange(fig1, fig2, nrow = 2)
```

creating variables

number- this variable identifies the number for each movie in the franchise

```{r}
#format the francise so it is not a list
extracted_data <- sapply(sequels$belongs_to_collection, `[[`, 1)  # Assuming first element is relevant
sequels$collection_info <- extracted_data 

```


Add a number for each movie in the franchise

```{r}
sequels <- sequels %>%
  group_by(collection_info) %>%
  mutate(number = rank(release_date))
```

Filter out movies that belonged to a franchise but there was only one movie in the franchise

```{r}
sequels <- sequels %>%
  group_by(collection_info) %>%
  filter(!all(number == 1))  # Filter groups where NOT all numbers are 1
```

```{r}
sequelsonly <- sequels %>%
  filter(number>1)

firstmovie <- sequels %>%
  filter(number == 1)
```


```{r}
sub_sequel <- sequels [, c("budget", "runtime", "vote_average", "revenue")]
correlation_matrix <- cor(sub_sequel, use = "pairwise")

sub_sequel <- sequelsonly [, c("budget", "runtime", "vote_average", "revenue")]
correlation_matrixseqonly <- cor(sub_sequel, use = "pairwise")

print(correlation_matrix)
print(correlation_matrixseqonly)


```


```{r}

if (any(sequels$budget <= 0)) {
  # Add a small constant (adjust as needed)
  data_adjusted <- sequels$budget + 1
} else {
  data_adjusted <- sequels$budget
}


# Apply log transformation (base-10 in this example)
sqrtnumber <- sqrt(data_adjusted)
sqrtnumber <- sqrt(sqrtnumber)
# Test normality of log-transformed data
shapiro.test(sqrtnumber)

logqqdata <- sqrtnumber
sequels$sqrt_budget <- logqqdata
theoretical_quantiles <- rnorm(length(logqqdata), mean(logqqdata), sd(logqqdata))

qq_sqrtbudget <- qqplot(logqqdata, theoretical_quantiles,
       main="Q-Q Plot of Budget Data",
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")
```


```{r}
# Square root transformation
rqqdata <- sequels$runtime
runtimetransformed <- sqrt(rqqdata)

shapiro.test(runtimetransformed)


sequels$runtime_sqrt <- runtimetransformed

theoretical_quantiles <- rnorm(length(runtimetransformed), mean(runtimetransformed), sd(runtimetransformed))
qq_runtime <- qqplot(runtimetransformed, theoretical_quantiles,
       main="Q-Q Plot of Runtime Data",
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")
```

```{r}
qqdata <- sequels$vote_average

theoretical_quantiles <- rnorm(length(qqdata), mean(qqdata), sd(qqdata))
shapiro.test(qqdata)
qq_vote_avg <- qqplot(qqdata, theoretical_quantiles,
       main="Q-Q Plot of Vote Average",
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")

```

```{r}
if (!require("gridExtra")) install.packages("gridExtra")
library(gridExtra)

if (any(sequels$number <= 0)) {
  # Add a small constant (adjust as needed)
  data_adjusted <- sequels$number + 1
} else {
  data_adjusted <- sequels$number
}

sqrtnumber <- sqrt(data_adjusted)

shapiro.test(sequels$number)
shapiro.test(expnum)
shapiro.test(sqrtnumber)

# Apply log transformation (base-10 in this example)
lognumber <- log10(data_adjusted)

# Test normality of log-transformed data
shapiro.test(lognumber)


qq_numberdata <- sqrtnumber

theoretical_quantiles <- rnorm(length(qq_numberdata), mean(qq_numberdata), sd(qq_numberdata))
qq_number <- qqplot(qq_numberdata, theoretical_quantiles,
       main="Q-Q Plot of Movie Number",
       ylab="Theoretical Quantiles", xlab="Sample Quantiles")


```

```{r}
sequels$log_budget <- logqqdata
sequels$log_number <- lognumber
```

```{r}
lm_model_seqonly <- lm(revenue ~ log_budget + log_number + vote_average + runtime_sqrt, data = sequelsonly)

lm_model <- lm(revenue ~ budget + number + vote_average + runtime, data = sequelsonly)
plot(lm_model_seqonly, which = 1)
summary(lm_model)
summary(lm_model_seqonly)
```

```{r}
ggplot(sequelsonly, aes(x = sqrt_budget, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Budget (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  scale_x_continuous(labels = c("25 M", "100 M", "225 M", "400 M"), breaks = c(sqrt(25000000), sqrt(100000000), sqrt(225000000), sqrt(400000000))) +
  xlab("Budget") +
  ylab("Revenue") +
  theme_grey()


```


```{r}
ggplot(sequelsonly, aes(x = runtime_sqrt, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Runtime (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  scale_x_continuous(labels = c(100, 144, 196, 256, 324), breaks = c(sqrt(100), sqrt(144), sqrt(196), sqrt(256), sqrt(324))) +
  xlab("Runtime") +
  ylab("Revenue") +
  theme_grey()
```


```{r}
ggplot(sequelsonly, aes(x = vote_average, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = revenue), color = "red") +
  labs(title = "Revenue vs. Vote Average Out of 10 (Sequel Movies Only")+
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  xlab("Vote Average Out of 10") +
  ylab("Revenue") +
  theme_grey()
```

```{r}
ggplot(sequels, aes(x = logqqdata, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = predicted_revenue), color = "red") +
  labs(title = "Revenue vs. Budget") +
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  scale_x_continuous(labels = c("6.25 M", "31.6 M", "100 M", "384.1 M"), breaks = c(sqrt(2500), sqrt(5625), sqrt(10000), sqrt(15625))) +
  xlab("Budget") +
  ylab("Revenue") +
  theme_grey()
```

```{r}
# Create the scatter plot
ggplot(sequels, aes(x = qqdata, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = predicted_revenue), color = "red") +
  labs(title = "Revenue vs. Vote Average (out of 10") +
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  xlab("Vote Average (out of 10)") +
  ylab("Revenue")+
  theme_grey()
  # Inverse transformation to get the actual budget values
```


```{r}
ggplot(sequels, aes(x = runtimetransformed, y = revenue)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = lm, aes(y = predicted_revenue), color = "red") +
  labs(title = "Revenue vs. Runtime (Minutes)") +
  scale_y_continuous(labels = scales::number_format(), breaks = seq(from = 0, to = 2000000000, by = 250000000)) +
  scale_x_continuous(labels = c(100, 144, 196, 256, 324), breaks = c(sqrt(100), sqrt(144), sqrt(196), sqrt(256), sqrt(324))) +
  xlab("Runtime (Minutes)")+
  theme_grey()
```

```{r}

new_min <- 0  # Adjust this value as needed (minimum vote average)
new_max <- 10  # Adjust this value as needed (maximum vote average)

# Combine data into a single data frame with a "category" variable
combined_data <- rbind(
  data.frame(vote_average = firstmovie$vote_average, category = "Movies that Recieved a Sequel"),
  data.frame(vote_average = nonsequels$vote_average, category = "Non-Sequels")
)

# Create the density plot
densityplot_vote <- ggplot(combined_data, aes(x = vote_average, color = category)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density Plot of Vote Average", x = "Vote Average", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max)) +  # Set new limits
  scale_color_manual(values = c("royalblue", "orange"))  # Set colors for each category

densityplot_vote
```


```{r}
new_min <- 50  # Adjust this value as needed (minimum vote average)
new_max <- 210  # Adjust this value as needed (maximum vote average)

# Combine data into a single data frame with a "category" variable
combined_data <- rbind(
  data.frame(runtime = firstmovie$runtime, category = "Movies that Recieved a Sequel"),
  data.frame(runtime = nonsequels$runtime, category = "Non-Sequels")
)

# Create the density plot
densityplot <- ggplot(combined_data, aes(x = runtime, color = category)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density Plot of Runtime", x = "Runtime", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max)) +  # Set new limits
  scale_color_manual(values = c("royalblue", "orange"))  # Set colors for each category

densityplot
```

```{r}
new_min <- 0  # Adjust this value as needed (minimum vote average)
new_max <- 260000000  # Adjust this value as needed (maximum vote average)

# Combine data into a single data frame with a "category" variable
combined_data <- rbind(
  data.frame(budget = firstmovie$budget, category = "Movies that Recieved a Sequel"),
  data.frame(budget = nonsequels$budget, category = "Non-Sequels")
)

# Create the density plot
densityplot <- ggplot(combined_data, aes(x = budget, color = category)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density Plot of Budget", x = "Budget", y = "Density") +
  theme_grey() +
  scale_x_continuous(limits = c(new_min, new_max)) +  # Set new limits
  scale_x_continuous(labels = c(1000000, 144, 196, 256, 324), breaks = c(sqrt(100), sqrt(144), sqrt(196), sqrt(256), sqrt(324))) +
  scale_color_manual(values = c("royalblue", "orange"))  # Set colors for each category
 

densityplot
```


```{r}
# Load required librar
# Your dataframe with 561 rows in one column, assuming it's named df
# Replace 'df' with the actual name of your dataframe
# Let's assume the column containing JSON data is named "genres"
json_column <- sequelsonly$genres  # Replace with the name of your column containing JSON data

# Function to correct JSON format
correct_json <- function(json_string) {
  # Replace single quotes with double quotes
  corrected_json <- gsub("'", "\"", json_string)
  return(corrected_json)
}

# Apply the correct_json function to each element of the json_column
corrected_json_column <- sapply(json_column, correct_json)

# Initialize a list to store the extracted names
all_names <- list()

# Loop through each element of the corrected_json_column
for (json_string in corrected_json_column) {
  # Parse the JSON string in the current row
  parsed_json <- jsonlite::fromJSON(json_string)
 
  # Extract the value of the 'name' key
  names <- parsed_json$name
 
  # Store the extracted names in the list
  all_names <- c(all_names, list(names))
}

# Determine the maximum number of genres in any movie
max_genres <- max(lengths(all_names))

# Pad shorter lists with NA to make them the same length
all_names <- lapply(all_names, function(x) c(x, rep(NA, max_genres - length(x))))

# Convert the list to a dataframe
all_names_df <- as.data.frame(do.call(rbind, all_names))

# Rename the columns
colnames(all_names_df) <- paste0("genress_", 1:max_genres)

# Join the extracted genre columns with the original dataset
sequelsonly <- cbind(sequelsonly, all_names_df)

# Print the joined dataframe
print(sequelsonly)
```

```{r}
movies_long <- sequelsonly %>%
  pivot_longer(cols = starts_with("Genress"),
               names_to = "Genre_Column",
               values_to = "Genre") %>%
  filter(!is.na(Genre))  # Remove rows with missing genre values

# Perform ANOVA
anova_result <- aov(revenue ~ Genre, data = movies_long)

# Print ANOVA table
print(summary(anova_result))
```

Calculating HSD to quantify the magnitude of differences in revenue between genres. Will help understand the significance of observed differences from anova


```{r}
# Load the necessary library
library(stats)

# Assuming your data frame is named "movie_data" and the column containing revenues is named "revenue"
# Assuming you have a column named "genre" indicating the genre of each movie

# Perform ANOVA
model <- lm(revenue ~ Genre, data = movies_long)
anova_result <- anova(model)

# Check the ANOVA result
print(anova_result)

# If the ANOVA is significant, proceed with Tukey's HSD test
if (anova_result$`Pr(>F)`[1] < 0.05) {
  tukey_result <- TukeyHSD(aov(model))
  print(tukey_result)
 
  significant_pairs <- as.data.frame(tukey_result$`Genre`)  # Extract pairs and adjusted p-values
  significant_pairs <- significant_pairs[significant_pairs$`p adj` < 0.05, ]  # Filter significant pairs
  print(significant_pairs)}
```


```{r}
# Load the necessary library

# Assuming your data frame is named "movie_data" and the column containing revenues is named "revenue"
# Assuming you have a column named "genre" indicating the genre of each movie

# Perform ANOVA
model <- lm(revenue ~ Genre, data = movies_long)
anova_result <- anova(model)

# Check the ANOVA result
print(anova_result)

# If the ANOVA is significant, proceed with Tukey's HSD test
if (anova_result$`Pr(>F)`[1] < 0.05) {
  tukey_result <- TukeyHSD(aov(model))
  print(tukey_result)
 
  # Extract significant pairs and adjusted p-values
  significant_pairs <- as.data.frame(tukey_result$`Genre`)
  significant_pairs <- significant_pairs[significant_pairs$`p adj` < 0.05, ]
  print(significant_pairs)
 
  # Visualize significant pairs
  barplot(significant_pairs$diff, names.arg = rownames(significant_pairs), ylim = c(min(significant_pairs$lwr), max(significant_pairs$upr)),
          xlab = "Genre Comparison", ylab = "Mean Difference", main = "Significant Genre Differences")
 
  # Add error bars
  arrows(x0 = 1:nrow(significant_pairs), y0 = significant_pairs$diff, y1 = significant_pairs$lwr, angle = 90, code = 3, length = 0.1)
} else {
  print("ANOVA is not significant, no need for post-hoc tests.")
}
```


```{r}
# Assuming your data frame is named 'movies_data'
# First, aggregate the data by Genre, calculating the mean revenue for each genre
avg_revenue <- movies_long %>%
  group_by(Genre) %>%
  summarise(avg_revenue = mean(revenue))

# Now, plot the aggregated data
ggplot(avg_revenue, aes(x = reorder(Genre, avg_revenue), y = avg_revenue)) +
  geom_bar(stat = "identity", fill = "royalblue") +
  labs(title = "Average Revenue by Genre (Sequels Only)", x = "Genre", y = "Average Revenue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar_format(prefix = "$"), breaks = seq(0, 500000000, by = 100000000))
```

```{r}
# Assuming your data is stored in a dataframe called "data" with columns "outcome_variable", "categorical_predictor", and possibly other covariates

# Fit linear regression model
lm_model <- lm(revenue ~ log_budget + vote_average + runtime_sqrt, data = sequelsonly)

# Perform ANOVA to check overall significance of categorical predictor
anova_lm <- anova(lm_model)

# Check ANOVA table
print(anova_lm)

# Extract p-value for the categorical predictor
p_value <- anova_lm$`Pr(>F)`[1]

```


